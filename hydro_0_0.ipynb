{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0/1 [..............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda3/lib/python3.6/site-packages/Keras-2.1.6-py3.6.egg/keras/engine/training.py:469: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras.backend as K\n",
    "from keras.layers import (Input, Dense, Reshape, Flatten, Lambda, merge,\n",
    "                          Dropout, BatchNormalization, Activation, Embedding)\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import (UpSampling2D, Conv2D, ZeroPadding2D,\n",
    "                                        AveragePooling2D)\n",
    "from keras.layers.local import LocallyConnected2D\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.optimizers import *\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from keras.models import load_model\n",
    "from skimage import transform,data\n",
    "\n",
    "RND = 777\n",
    "np.random.seed(RND)\n",
    "\n",
    "RUN = 'B'\n",
    "OUT_DIR = 'out/' + RUN\n",
    "TENSORBOARD_DIR = 'tensorboard/wgans/' + RUN\n",
    "if not os.path.isdir(OUT_DIR): os.makedirs(OUT_DIR)\n",
    "if not os.path.isdir(TENSORBOARD_DIR): os.makedirs(TENSORBOARD_DIR)\n",
    "\n",
    "X_train = np.zeros((20,8,8,1))\n",
    "for i in range(0,8):\n",
    "    for j in range(0,8):\n",
    "        if i==3 or i==4:\n",
    "            if j>0 and j<7:\n",
    "                X_train[:,i,j,:]+=1\n",
    "        if j==3 or j==4:\n",
    "            if i>0 and i<7:\n",
    "                X_train[:,i,j,:]+=1\n",
    "#plt.imshow(img[1,:,:], cmap='gray')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "\n",
    "def generator(latent_size):\n",
    "    \n",
    "    latent = Input(shape=(latent_size,))\n",
    "    x = Dense(2*2*8)(latent)\n",
    "    x = Reshape((2,2,8))(x)\n",
    "    x = UpSampling2D(size=(2,2))(x)\n",
    "    \n",
    "    x = ZeroPadding2D((1,1))(x)\n",
    "    x = LocallyConnected2D(4, (3, 3), kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = UpSampling2D(size=(2,2))(x)\n",
    "    \n",
    "    x = ZeroPadding2D((2,2))(x)\n",
    "    x = LocallyConnected2D(4, (5, 5), kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "    x = ZeroPadding2D((1,1))(x)\n",
    "    x = LocallyConnected2D(1, (3, 3), kernel_initializer='glorot_normal')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return Model(inputs=latent, outputs=x)\n",
    "\n",
    "def discriminator():\n",
    "    \n",
    "    image = Input(shape=(8,8,1))\n",
    "    \n",
    "    x = Conv2D(16, (4, 4), padding='same')(image)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.1)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = ZeroPadding2D((1,1))(x)\n",
    "    x = LocallyConnected2D(8, (3, 3), padding='valid', strides=(2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = ZeroPadding2D((1,1))(x)\n",
    "    x = LocallyConnected2D(8, (3, 3), padding='valid', strides=(2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(inputs=image, outputs=x)\n",
    "\n",
    "def d_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "def resize_with_resolution(resize,img):\n",
    "    x = resize[1]\n",
    "    y = resize[0]\n",
    "    width = len(img[1])\n",
    "    height = len(img[0])\n",
    "    img2 = np.zeros((width*x,height*y))\n",
    "    for i in range(width):\n",
    "        for j in range(height):\n",
    "            img2[x*i:x*(i+1),y*j:y*(j+1)] = img[i,j]\n",
    "    return img2\n",
    "\n",
    "# save 10x10 sample of generated images\n",
    "\n",
    "\n",
    "Z_SIZE = 5\n",
    "    \n",
    "D = discriminator()\n",
    "\n",
    "D.compile(optimizer=RMSprop(lr=0.00005),loss=d_loss)\n",
    "\n",
    "input_z = Input(shape=(Z_SIZE, ), name='input_z_')\n",
    "\n",
    "G = generator(Z_SIZE)\n",
    "\n",
    "# create combined D(G) model\n",
    "output_is_fake = D(G(inputs=[input_z]))\n",
    "DG = Model(inputs=input_z, outputs=output_is_fake)\n",
    "\n",
    "DG.compile(optimizer=RMSprop(lr=0.00005),loss=d_loss)\n",
    "\n",
    "def generate_samples(n=0, save=True):\n",
    "\n",
    "    zz = np.random.normal(0., 1., (9, Z_SIZE))\n",
    "    generated_images = G.predict(zz)\n",
    "\n",
    "    rr = []\n",
    "    for c in range(3):\n",
    "        rr.append(\n",
    "            np.concatenate(generated_images[c * 3:(1 + c) * 3]).reshape(24, 8))\n",
    "    img = np.hstack(rr)\n",
    "    img = resize_with_resolution((20,20),img)\n",
    "    \n",
    "    if save:\n",
    "        plt.imsave(OUT_DIR + '/samples_%07d.png' % n, img, cmap=plt.cm.gray)\n",
    "\n",
    "    return img\n",
    "\n",
    "# write tensorboard summaries\n",
    "sw = tf.summary.FileWriter(TENSORBOARD_DIR)\n",
    "def update_tb_summary(step, write_sample_images=True):\n",
    "\n",
    "    s = tf.Summary()\n",
    "\n",
    "    # losses as is\n",
    "    for names, vals in zip(('D_real_is_fake'\n",
    "                            'D_fake_is_fake', 'DG_is_fake'),\n",
    "                           (D_true_losses, D_fake_losses, DG_losses)):\n",
    "\n",
    "        v = s.value.add()\n",
    "        v.simple_value = vals[1]\n",
    "        v.tag = names[0]\n",
    "\n",
    "        v = s.value.add()\n",
    "        v.simple_value = vals[2]\n",
    "        v.tag = names[1]\n",
    "\n",
    "    # D loss: -1*D_true_is_fake - D_fake_is_fake\n",
    "    v = s.value.add()\n",
    "    v.simple_value = -D_true_losses[-1] - D_fake_losses[-1]\n",
    "    v.tag = 'D loss (-1*D_real_is_fake - D_fake_is_fake)'\n",
    "\n",
    "    # generated image\n",
    "    if write_sample_images:\n",
    "        img = generate_samples(step, save=True)\n",
    "        s.MergeFromString(tf.Session().run(\n",
    "            tf.summary.image('samples_%07d' % step,\n",
    "                             img.reshape([1, *img.shape, 1]))))\n",
    "\n",
    "    sw.add_summary(s, step)\n",
    "    sw.flush()\n",
    "    \n",
    "ITERATIONS = 1\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "progress_bar = Progbar(target=ITERATIONS)\n",
    "\n",
    "DG_losses = []\n",
    "D_true_losses = []\n",
    "D_fake_losses = []\n",
    "\n",
    "\n",
    "for it in range(ITERATIONS):\n",
    "\n",
    "    if len(D_true_losses) > 0:\n",
    "        progress_bar.update(\n",
    "            it,\n",
    "            values=[ # avg of 5 most recent\n",
    "                    ('D_real_is_fake', np.mean(D_true_losses[-5:], axis=0)),\n",
    "                    ('D_fake_is_fake', np.mean(D_fake_losses[-5:], axis=0)),\n",
    "                    ('D(G)_is_fake', np.mean(DG_losses[-5:],axis=0)),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        progress_bar.update(it)\n",
    "\n",
    "    # 1: train D on real+generated images\n",
    "\n",
    "    if (it % 1000) < 25 or it % 500 == 0: # 25 times in 1000, every 500th\n",
    "        d_iters = 100\n",
    "    else:\n",
    "        d_iters = 5\n",
    "\n",
    "    for d_it in range(d_iters):\n",
    "\n",
    "        # unfreeze D\n",
    "        D.trainable = True\n",
    "        for l in D.layers: l.trainable = True\n",
    "\n",
    "        # clip D weights\n",
    "\n",
    "        for l in D.layers:\n",
    "            weights = l.get_weights()\n",
    "            weights = [np.clip(w, -0.01, 0.01) for w in weights]\n",
    "            l.set_weights(weights)\n",
    "\n",
    "        # 1.1: maximize D output on reals === minimize -1*(D(real))\n",
    "\n",
    "        # draw random samples from real images\n",
    "        index = np.random.choice(len(X_train), BATCH_SIZE, replace=False)\n",
    "        real_images = X_train[index]\n",
    "\n",
    "        D_loss = D.train_on_batch(real_images, -np.ones(BATCH_SIZE))\n",
    "        D_true_losses.append(D_loss)\n",
    "\n",
    "        # 1.2: minimize D output on fakes \n",
    "\n",
    "        zz = np.random.normal(0., 1., (BATCH_SIZE, Z_SIZE))\n",
    "        generated_images = G.predict(zz)\n",
    "\n",
    "        D_loss = D.train_on_batch(generated_images, np.ones(BATCH_SIZE))\n",
    "        D_fake_losses.append(D_loss)\n",
    "\n",
    "    # 2: train D(G) (D is frozen)\n",
    "    # minimize D output while supplying it with fakes, \n",
    "    # telling it that they are reals (-1)\n",
    "\n",
    "    # freeze D\n",
    "    D.trainable = False\n",
    "    for l in D.layers: l.trainable = False\n",
    "\n",
    "    zz = np.random.normal(0., 1., (BATCH_SIZE, Z_SIZE)) \n",
    "\n",
    "    DG_loss = DG.train_on_batch(zz,-np.ones(BATCH_SIZE))\n",
    "\n",
    "    DG_losses.append(DG_loss)\n",
    "\n",
    "    if it % 10 == 0:\n",
    "        update_tb_summary(it, write_sample_images=(it % 250 == 0))\n",
    "\n",
    "DG.save('DG.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
